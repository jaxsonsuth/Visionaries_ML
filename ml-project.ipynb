{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e93edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:38:58.208694Z",
     "iopub.status.busy": "2024-12-05T07:38:58.207773Z",
     "iopub.status.idle": "2024-12-05T07:39:03.588863Z",
     "shell.execute_reply": "2024-12-05T07:39:03.588166Z"
    },
    "papermill": {
     "duration": 5.387538,
     "end_time": "2024-12-05T07:39:03.590801",
     "exception": false,
     "start_time": "2024-12-05T07:38:58.203263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##IMPORTS\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import random_split \n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d19ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:03.597974Z",
     "iopub.status.busy": "2024-12-05T07:39:03.597622Z",
     "iopub.status.idle": "2024-12-05T07:39:04.316898Z",
     "shell.execute_reply": "2024-12-05T07:39:04.315948Z"
    },
    "papermill": {
     "duration": 0.725238,
     "end_time": "2024-12-05T07:39:04.319219",
     "exception": false,
     "start_time": "2024-12-05T07:39:03.593981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple' 'apricot' 'avocado' 'banana' 'beet' 'cabbage' 'carrot' 'corn'\n",
      " 'cucumber' 'daikon' 'garlic' 'grape' 'grapefruit' 'kiwi' 'lemon' 'lime'\n",
      " 'mango' 'melon' 'onion' 'orange' 'nectarine' 'pomelo' 'pear' 'pepper'\n",
      " 'plum' 'pomegranate' 'potato' 'pumpkin' 'raddish' 'salad' 'tangerine'\n",
      " 'tomato' 'watermelon' 'zucchini']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2843917886.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/kaggle/input/packed-fruits-and-vegetables-recognition-benchmark/variety_classification.csv')\n"
     ]
    }
   ],
   "source": [
    "#TEST VALID TRAIN SPLIT\n",
    "df = pd.read_csv('/kaggle/input/packed-fruits-and-vegetables-recognition-benchmark/variety_classification.csv')\n",
    "df.drop(['layout_id', 'for_cropping', 'packed', 'amount', 'uniform_background', 'spoiled', 'weight', 'cam', 'city', 'crowd', 'date', 'simp_amount', 'shop'], axis=1, inplace=True)\n",
    "train_df = df[df['subset'] == 'train']\n",
    "train_df.loc[:, 'variety_image_path'] = train_df['variety_image_path'].str.replace(\n",
    "    'varieties_classification_dataset/train/', '', regex=False)\n",
    "\n",
    "\n",
    "test_df = df[df['subset'] == 'test']\n",
    "test_df.loc[:, 'variety_image_path'] = test_df['variety_image_path'].str.replace(\n",
    "    'varieties_classification_dataset/test/', '', regex=False)\n",
    "\n",
    "\n",
    "labels = df['species'].unique()\n",
    "label_to_int = {label: idx for idx, label in enumerate(labels)}\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d1b8b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:04.326064Z",
     "iopub.status.busy": "2024-12-05T07:39:04.325456Z",
     "iopub.status.idle": "2024-12-05T07:39:04.331197Z",
     "shell.execute_reply": "2024-12-05T07:39:04.330396Z"
    },
    "papermill": {
     "duration": 0.010888,
     "end_time": "2024-12-05T07:39:04.332865",
     "exception": false,
     "start_time": "2024-12-05T07:39:04.321977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMAGE DATASET\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label_to_int = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_name = os.path.join(self.root_dir, row['variety_image_path'])\n",
    "        label = self.label_to_int[row['species']]\n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eda2f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:04.339475Z",
     "iopub.status.busy": "2024-12-05T07:39:04.339058Z",
     "iopub.status.idle": "2024-12-05T07:39:04.343288Z",
     "shell.execute_reply": "2024-12-05T07:39:04.342503Z"
    },
    "papermill": {
     "duration": 0.009345,
     "end_time": "2024-12-05T07:39:04.345095",
     "exception": false,
     "start_time": "2024-12-05T07:39:04.335750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#VGG16 - TRANSFORM\n",
    "vgg_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f341cabc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:04.351341Z",
     "iopub.status.busy": "2024-12-05T07:39:04.351103Z",
     "iopub.status.idle": "2024-12-05T07:39:07.152374Z",
     "shell.execute_reply": "2024-12-05T07:39:07.151546Z"
    },
    "papermill": {
     "duration": 2.806367,
     "end_time": "2024-12-05T07:39:07.154312",
     "exception": false,
     "start_time": "2024-12-05T07:39:04.347945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "###MODEL - VGG16\n",
    "model = models.vgg16()\n",
    "num_classes = len(labels)\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, num_classes)\n",
    ")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Available GPUs: {num_gpus}\")\n",
    "\n",
    "if num_gpus > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e9dac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:07.162473Z",
     "iopub.status.busy": "2024-12-05T07:39:07.162159Z",
     "iopub.status.idle": "2024-12-05T07:39:07.168116Z",
     "shell.execute_reply": "2024-12-05T07:39:07.167325Z"
    },
    "papermill": {
     "duration": 0.012126,
     "end_time": "2024-12-05T07:39:07.169585",
     "exception": false,
     "start_time": "2024-12-05T07:39:07.157459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'###CNN - TRANSFORM\\n\\ncnn_transform = transforms.Compose([\\n    transforms.Resize((64, 64)),\\n    transforms.ToTensor(),\\n    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\\n])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"###CNN - TRANSFORM\n",
    "\n",
    "cnn_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0909e1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:07.175941Z",
     "iopub.status.busy": "2024-12-05T07:39:07.175674Z",
     "iopub.status.idle": "2024-12-05T07:39:07.181118Z",
     "shell.execute_reply": "2024-12-05T07:39:07.180321Z"
    },
    "papermill": {
     "duration": 0.01054,
     "end_time": "2024-12-05T07:39:07.182770",
     "exception": false,
     "start_time": "2024-12-05T07:39:07.172230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'###CUSTOM CNN###\\n\\nclass CustomCNN(nn.Module):\\n    def __init__(self, num_classes=len(labels)):  # Number of classes for classification\\n        super(CustomCNN, self).__init__()\\n        \\n        # Define the layers of the model\\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Input is RGB, 3 channels\\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\\n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\\n        \\n        # Define the fully connected layers\\n        self.fc1 = nn.Linear(256 * 8 * 8, 1024) \\n        self.fc2 = nn.Linear(1024, num_classes)\\n        \\n    def forward(self, x):\\n        # Apply the layers\\n        x = F.relu(self.conv1(x))\\n        x = F.max_pool2d(x, 2)  # Pool after each conv layer\\n\\n        x = F.relu(self.conv2(x))\\n        x = F.max_pool2d(x, 2)\\n\\n        x = F.relu(self.conv3(x))\\n        x = F.max_pool2d(x, 2)\\n\\n        x = torch.flatten(x, 1)  # Flatten the tensor for the fully connected layers\\n        x = F.relu(self.fc1(x))\\n        x = self.fc2(x)\\n\\n        return x\\n\\nmodel = CustomCNN()\\nfor param in model.parameters():\\n    param.requires_grad = True \\n\\n\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nnum_gpus = torch.cuda.device_count()\\nprint(f\"Available GPUs: {num_gpus}\")\\n\\nif num_gpus > 1:\\n    model = nn.DataParallel(model)\\n    model = model.to(device)\\nelse:\\n    model = model.to(device)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"###CUSTOM CNN###\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=len(labels)):  # Number of classes for classification\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Define the layers of the model\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Input is RGB, 3 channels\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 1024) \n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)  # Pool after each conv layer\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = torch.flatten(x, 1)  # Flatten the tensor for the fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomCNN()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Available GPUs: {num_gpus}\")\n",
    "\n",
    "if num_gpus > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    model = model.to(device)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9bb99da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:07.189862Z",
     "iopub.status.busy": "2024-12-05T07:39:07.189356Z",
     "iopub.status.idle": "2024-12-05T07:39:07.206757Z",
     "shell.execute_reply": "2024-12-05T07:39:07.205979Z"
    },
    "papermill": {
     "duration": 0.022805,
     "end_time": "2024-12-05T07:39:07.208585",
     "exception": false,
     "start_time": "2024-12-05T07:39:07.185780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##DATASET AND LOADER\n",
    "tf = vgg_transform\n",
    "\n",
    "train_valid_dataset = ImageDataset(dataframe=train_df, root_dir='/kaggle/input/packed-fruits-and-vegetables-recognition-benchmark/train/train', transform = tf)\n",
    "train_size = int(0.8 * len(train_valid_dataset))\n",
    "val_size = len(train_valid_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_valid_dataset, [train_size, val_size])\n",
    "test_dataset = ImageDataset(dataframe=test_df, root_dir='/kaggle/input/packed-fruits-and-vegetables-recognition-benchmark/test/test', transform = tf)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c0a9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:07.217444Z",
     "iopub.status.busy": "2024-12-05T07:39:07.217202Z",
     "iopub.status.idle": "2024-12-05T07:39:07.221639Z",
     "shell.execute_reply": "2024-12-05T07:39:07.220826Z"
    },
    "papermill": {
     "duration": 0.010832,
     "end_time": "2024-12-05T07:39:07.223280",
     "exception": false,
     "start_time": "2024-12-05T07:39:07.212448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###PARAMS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46eb67d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T07:39:07.230128Z",
     "iopub.status.busy": "2024-12-05T07:39:07.229888Z",
     "iopub.status.idle": "2024-12-05T09:45:33.178548Z",
     "shell.execute_reply": "2024-12-05T09:45:33.177443Z"
    },
    "papermill": {
     "duration": 7586.318036,
     "end_time": "2024-12-05T09:45:33.544355",
     "exception": false,
     "start_time": "2024-12-05T07:39:07.226319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Training):   0%|          | 0/510 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "Epoch 1/10 (Training): 100%|██████████| 510/510 [10:17<00:00,  1.21s/batch, accuracy=16.6, loss=2.94]\n",
      "Epoch 1/10 (Validation): 100%|██████████| 510/510 [02:40<00:00,  3.18batch/s, accuracy=24.2, loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.9407, Train Accuracy: 16.63%, Val Loss: 2.4719, Val Accuracy: 24.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 (Training): 100%|██████████| 510/510 [10:35<00:00,  1.25s/batch, accuracy=33.7, loss=2.11]\n",
      "Epoch 2/10 (Validation): 100%|██████████| 510/510 [02:17<00:00,  3.70batch/s, accuracy=49, loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 2.1091, Train Accuracy: 33.70%, Val Loss: 1.5815, Val Accuracy: 48.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 (Training): 100%|██████████| 510/510 [09:59<00:00,  1.18s/batch, accuracy=53.5, loss=1.44]\n",
      "Epoch 3/10 (Validation): 100%|██████████| 510/510 [02:26<00:00,  3.49batch/s, accuracy=67.2, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 1.4392, Train Accuracy: 53.53%, Val Loss: 1.0311, Val Accuracy: 67.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 (Training): 100%|██████████| 510/510 [10:33<00:00,  1.24s/batch, accuracy=69.7, loss=0.945]\n",
      "Epoch 4/10 (Validation): 100%|██████████| 510/510 [02:15<00:00,  3.76batch/s, accuracy=79.4, loss=0.638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.9450, Train Accuracy: 69.66%, Val Loss: 0.6381, Val Accuracy: 79.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 (Training): 100%|██████████| 510/510 [10:07<00:00,  1.19s/batch, accuracy=79.9, loss=0.632]\n",
      "Epoch 5/10 (Validation): 100%|██████████| 510/510 [02:14<00:00,  3.79batch/s, accuracy=84.2, loss=0.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.6318, Train Accuracy: 79.86%, Val Loss: 0.5029, Val Accuracy: 84.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 (Training): 100%|██████████| 510/510 [10:06<00:00,  1.19s/batch, accuracy=90.4, loss=0.298]\n",
      "Epoch 6/10 (Validation): 100%|██████████| 510/510 [02:18<00:00,  3.69batch/s, accuracy=90.1, loss=0.316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.2978, Train Accuracy: 90.39%, Val Loss: 0.3164, Val Accuracy: 90.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 (Training): 100%|██████████| 510/510 [10:23<00:00,  1.22s/batch, accuracy=92.3, loss=0.238]\n",
      "Epoch 7/10 (Validation): 100%|██████████| 510/510 [02:18<00:00,  3.69batch/s, accuracy=90.9, loss=0.294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.2382, Train Accuracy: 92.29%, Val Loss: 0.2937, Val Accuracy: 90.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 (Training): 100%|██████████| 510/510 [10:17<00:00,  1.21s/batch, accuracy=93.4, loss=0.205]\n",
      "Epoch 8/10 (Validation): 100%|██████████| 510/510 [02:32<00:00,  3.35batch/s, accuracy=91.5, loss=0.276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.2046, Train Accuracy: 93.43%, Val Loss: 0.2762, Val Accuracy: 91.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 (Training): 100%|██████████| 510/510 [10:12<00:00,  1.20s/batch, accuracy=94.3, loss=0.177]\n",
      "Epoch 9/10 (Validation): 100%|██████████| 510/510 [02:23<00:00,  3.55batch/s, accuracy=92, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.1768, Train Accuracy: 94.30%, Val Loss: 0.2615, Val Accuracy: 92.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 (Training): 100%|██████████| 510/510 [10:09<00:00,  1.19s/batch, accuracy=94.9, loss=0.157]\n",
      "Epoch 10/10 (Validation): 100%|██████████| 510/510 [02:16<00:00,  3.73batch/s, accuracy=92.6, loss=0.245]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.1573, Train Accuracy: 94.93%, Val Loss: 0.2446, Val Accuracy: 92.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###TRAIN\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Training)\", unit=\"batch\") as tepoch:\n",
    "        for inputs, labels in tepoch:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            tepoch.set_postfix(loss=train_loss / (tepoch.n + 1), accuracy=100 * correct / total)\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Validation)\", unit=\"batch\") as vepoch:\n",
    "            for inputs, labels in vepoch:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                vepoch.set_postfix(loss=val_loss / (vepoch.n + 1), accuracy=100 * val_correct / val_total)\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Step the learning rate scheduler, if used\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50a5641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:45:35.497372Z",
     "iopub.status.busy": "2024-12-05T09:45:35.496996Z",
     "iopub.status.idle": "2024-12-05T09:49:01.308441Z",
     "shell.execute_reply": "2024-12-05T09:49:01.307343Z"
    },
    "papermill": {
     "duration": 206.773092,
     "end_time": "2024-12-05T09:49:01.310145",
     "exception": false,
     "start_time": "2024-12-05T09:45:34.537053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 172/172 [03:25<00:00,  1.20s/batch, accuracy=91.7, loss=0.288]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2879, Test Accuracy: 91.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to compute gradients during evaluation\n",
    "    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as tepoch:\n",
    "        for inputs, labels in tepoch:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass: Get the predictions from the model\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar with loss and accuracy\n",
    "            tepoch.set_postfix(loss=test_loss / (tepoch.n + 1), accuracy=100 * correct / total)\n",
    "\n",
    "# Calculate final test accuracy and loss\n",
    "test_accuracy = 100 * correct / total\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f26f08",
   "metadata": {
    "papermill": {
     "duration": 0.959102,
     "end_time": "2024-12-05T09:49:03.242429",
     "exception": false,
     "start_time": "2024-12-05T09:49:02.283327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4522892,
     "sourceId": 9203638,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7810.170486,
   "end_time": "2024-12-05T09:49:05.863103",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-05T07:38:55.692617",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
